{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_target = pd.read_csv('target.csv', sep=' ')\n",
    "pd_non_target = pd.read_csv('non_target.csv', sep=' ')\n",
    "np_target = pd_target.values\n",
    "np_non_target = pd_non_target.values\n",
    "\n",
    "target = np_target\n",
    "non_target = np_non_target\n",
    "\n",
    "np_label = np.ones(len(target))\n",
    "np_non_label = np.zeros(len(non_target))\n",
    "\n",
    "train = np.concatenate((target, non_target),axis=0) \n",
    "label = np.append(np_label, np_non_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "59\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(train[0]))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(train.shape[0])\n",
    "train_data = train[indices]\n",
    "train_targets = label[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    l2 = regularizers.l2(0.1)\n",
    "    init = initializers.he_uniform()\n",
    "    model.add(layers.Dense(input_dim=len(train[0]), units=1024, activation='relu'\n",
    "                            ,kernel_regularizer=l2\n",
    "                            ,kernel_initializer=init))  \n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(units=1024, activation='relu'\n",
    "                                ,kernel_regularizer=l2\n",
    "                                ,kernel_initializer=init))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(units=1024, activation='relu'\n",
    "                                ,kernel_regularizer=l2\n",
    "                                ,kernel_initializer=init))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 68 samples, validate on 34 samples\n",
      "Epoch 1/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 500.0249 - acc: 0.5735 - val_loss: 385.3693 - val_acc: 0.9118\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 322.4790 - acc: 0.8235 - val_loss: 259.1324 - val_acc: 0.7647\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 222.2526 - acc: 0.7500 - val_loss: 183.9518 - val_acc: 0.8824\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 160.6621 - acc: 0.8529 - val_loss: 135.9343 - val_acc: 0.8824\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 120.2795 - acc: 0.8382 - val_loss: 103.3872 - val_acc: 0.7647\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 92.1666 - acc: 0.8824 - val_loss: 79.9924 - val_acc: 0.8824\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 71.8321 - acc: 0.8382 - val_loss: 62.8295 - val_acc: 0.8529\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 56.5193 - acc: 0.8971 - val_loss: 49.6999 - val_acc: 0.8235\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 44.7628 - acc: 0.9118 - val_loss: 39.4491 - val_acc: 0.8824\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 35.7005 - acc: 0.8529 - val_loss: 31.4604 - val_acc: 0.8824\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 28.4479 - acc: 0.8824 - val_loss: 25.0881 - val_acc: 0.8235\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 22.5937 - acc: 0.8676 - val_loss: 20.0060 - val_acc: 0.8235\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 17.9566 - acc: 0.9265 - val_loss: 15.8375 - val_acc: 0.7647\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 14.2100 - acc: 0.8824 - val_loss: 12.4984 - val_acc: 0.7647\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 11.1751 - acc: 0.8382 - val_loss: 9.7906 - val_acc: 0.8529\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8.6818 - acc: 0.9118 - val_loss: 7.6974 - val_acc: 0.7941\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 6.7398 - acc: 0.8971 - val_loss: 5.8707 - val_acc: 0.8824\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.1429 - acc: 0.8824 - val_loss: 4.4956 - val_acc: 0.8529\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 3.9409 - acc: 0.9118 - val_loss: 3.4617 - val_acc: 0.8529\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 3.0358 - acc: 0.8824 - val_loss: 2.6327 - val_acc: 0.8824\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 2.2506 - acc: 0.9118 - val_loss: 1.9879 - val_acc: 0.8529\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.7484 - acc: 0.8676 - val_loss: 1.5527 - val_acc: 0.8824\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.3584 - acc: 0.8529 - val_loss: 1.2326 - val_acc: 0.8529\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0825 - acc: 0.8824 - val_loss: 0.9926 - val_acc: 0.8529\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8881 - acc: 0.8529 - val_loss: 0.9033 - val_acc: 0.8529\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7473 - acc: 0.9118 - val_loss: 0.8062 - val_acc: 0.8529\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.6989 - acc: 0.8824 - val_loss: 0.8411 - val_acc: 0.7647\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6294 - acc: 0.8824 - val_loss: 0.6558 - val_acc: 0.8235\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6279 - acc: 0.8676 - val_loss: 0.7947 - val_acc: 0.7941\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6147 - acc: 0.8971 - val_loss: 0.6193 - val_acc: 0.8529\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6147 - acc: 0.8088 - val_loss: 0.6064 - val_acc: 0.8824\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5965 - acc: 0.8676 - val_loss: 0.6466 - val_acc: 0.8824\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6002 - acc: 0.8529 - val_loss: 0.6142 - val_acc: 0.8235\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5787 - acc: 0.8971 - val_loss: 0.6670 - val_acc: 0.8235\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5570 - acc: 0.8971 - val_loss: 0.9220 - val_acc: 0.7941\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5897 - acc: 0.8676 - val_loss: 0.7054 - val_acc: 0.8235\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5829 - acc: 0.8382 - val_loss: 0.6819 - val_acc: 0.8529\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5720 - acc: 0.8382 - val_loss: 0.5997 - val_acc: 0.8824\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5199 - acc: 0.9118 - val_loss: 0.5685 - val_acc: 0.8235\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5981 - acc: 0.8235 - val_loss: 0.6236 - val_acc: 0.8824\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 0.5805 - acc: 0.8824 - val_loss: 0.5758 - val_acc: 0.8529\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 0.5530 - acc: 0.8824 - val_loss: 0.6246 - val_acc: 0.8824\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5547 - acc: 0.8824 - val_loss: 0.5665 - val_acc: 0.8235\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5158 - acc: 0.8676 - val_loss: 0.5634 - val_acc: 0.8529\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5524 - acc: 0.8529 - val_loss: 0.5976 - val_acc: 0.8824\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5537 - acc: 0.8676 - val_loss: 0.6935 - val_acc: 0.8529\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4837 - acc: 0.9412 - val_loss: 0.5572 - val_acc: 0.8235\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5107 - acc: 0.8971 - val_loss: 0.6358 - val_acc: 0.8824\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5192 - acc: 0.8824 - val_loss: 0.5859 - val_acc: 0.8529\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5260 - acc: 0.8676 - val_loss: 0.5642 - val_acc: 0.8529\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5642 - acc: 0.8382 - val_loss: 0.7256 - val_acc: 0.7647\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5405 - acc: 0.8382 - val_loss: 0.7201 - val_acc: 0.8235\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5552 - acc: 0.8529 - val_loss: 0.7017 - val_acc: 0.8235\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5433 - acc: 0.8824 - val_loss: 0.5824 - val_acc: 0.8824\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5218 - acc: 0.9118 - val_loss: 0.5463 - val_acc: 0.8235\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5163 - acc: 0.8676 - val_loss: 0.5543 - val_acc: 0.8529\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5043 - acc: 0.8676 - val_loss: 0.5901 - val_acc: 0.8824\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5262 - acc: 0.8971 - val_loss: 0.5497 - val_acc: 0.8235\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5259 - acc: 0.8529 - val_loss: 0.5814 - val_acc: 0.8824\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5256 - acc: 0.9118 - val_loss: 0.5962 - val_acc: 0.8824\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4875 - acc: 0.9118 - val_loss: 0.5925 - val_acc: 0.8235\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5133 - acc: 0.8529 - val_loss: 0.5698 - val_acc: 0.8529\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5065 - acc: 0.8824 - val_loss: 0.6425 - val_acc: 0.8235\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5535 - acc: 0.8529 - val_loss: 0.6771 - val_acc: 0.8529\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5443 - acc: 0.8676 - val_loss: 0.5551 - val_acc: 0.8529\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4919 - acc: 0.8824 - val_loss: 0.7090 - val_acc: 0.8235\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4980 - acc: 0.8971 - val_loss: 0.5571 - val_acc: 0.8529\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4786 - acc: 0.9118 - val_loss: 0.5300 - val_acc: 0.8529\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4963 - acc: 0.9118 - val_loss: 0.5475 - val_acc: 0.8235\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5016 - acc: 0.8676 - val_loss: 0.6659 - val_acc: 0.8529\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4658 - acc: 0.9412 - val_loss: 0.6170 - val_acc: 0.8235\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5043 - acc: 0.8529 - val_loss: 0.5676 - val_acc: 0.8824\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4989 - acc: 0.8971 - val_loss: 0.6014 - val_acc: 0.8824\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4938 - acc: 0.8824 - val_loss: 0.6266 - val_acc: 0.8235\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4840 - acc: 0.8676 - val_loss: 0.5872 - val_acc: 0.8824\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5418 - acc: 0.8676 - val_loss: 0.6343 - val_acc: 0.8529\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4935 - acc: 0.8824 - val_loss: 0.6064 - val_acc: 0.8824\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4749 - acc: 0.9118 - val_loss: 0.6669 - val_acc: 0.8235\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4807 - acc: 0.8971 - val_loss: 0.6192 - val_acc: 0.8824\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4629 - acc: 0.8971 - val_loss: 0.5422 - val_acc: 0.8235\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4648 - acc: 0.9118 - val_loss: 0.5221 - val_acc: 0.8824\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4423 - acc: 0.9412 - val_loss: 0.5263 - val_acc: 0.8529\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5104 - acc: 0.892 - 0s 4ms/step - loss: 0.5110 - acc: 0.8971 - val_loss: 0.5290 - val_acc: 0.8529\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.5131 - acc: 0.9118 - val_loss: 0.5432 - val_acc: 0.8529\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4511 - acc: 0.8971 - val_loss: 0.5159 - val_acc: 0.8235\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4869 - acc: 0.8529 - val_loss: 0.5345 - val_acc: 0.8529\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4965 - acc: 0.8971 - val_loss: 0.5109 - val_acc: 0.8529\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4670 - acc: 0.9265 - val_loss: 0.5614 - val_acc: 0.8824\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4628 - acc: 0.9265 - val_loss: 0.5521 - val_acc: 0.8824\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4673 - acc: 0.9265 - val_loss: 0.6326 - val_acc: 0.8529\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4293 - acc: 0.9265 - val_loss: 0.5770 - val_acc: 0.8235\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4933 - acc: 0.8971 - val_loss: 0.5182 - val_acc: 0.8235\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4736 - acc: 0.9265 - val_loss: 0.7548 - val_acc: 0.7647\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4913 - acc: 0.9118 - val_loss: 0.5584 - val_acc: 0.8824\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5169 - acc: 0.8824 - val_loss: 0.5127 - val_acc: 0.8529\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4268 - acc: 0.9118 - val_loss: 0.6465 - val_acc: 0.8235\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4556 - acc: 0.9265 - val_loss: 0.6469 - val_acc: 0.8824\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4545 - acc: 0.9412 - val_loss: 0.5335 - val_acc: 0.8529\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4592 - acc: 0.9118 - val_loss: 0.5199 - val_acc: 0.8529\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4614 - acc: 0.9412 - val_loss: 0.5307 - val_acc: 0.8529\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5111 - acc: 0.8824 - val_loss: 0.5132 - val_acc: 0.8235\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4459 - acc: 0.9118 - val_loss: 0.5975 - val_acc: 0.8235\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4828 - acc: 0.8824 - val_loss: 0.7055 - val_acc: 0.7941\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4568 - acc: 0.9118 - val_loss: 0.6268 - val_acc: 0.8235\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4780 - acc: 0.8529 - val_loss: 0.5170 - val_acc: 0.8235\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4763 - acc: 0.8676 - val_loss: 0.5353 - val_acc: 0.8824\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4299 - acc: 0.9559 - val_loss: 0.5270 - val_acc: 0.8235\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4171 - acc: 0.9118 - val_loss: 0.6024 - val_acc: 0.8824\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4212 - acc: 0.9412 - val_loss: 0.6175 - val_acc: 0.8824\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4989 - acc: 0.8676 - val_loss: 0.5225 - val_acc: 0.8529\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4751 - acc: 0.8529 - val_loss: 0.6896 - val_acc: 0.7941\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4362 - acc: 0.9412 - val_loss: 0.5802 - val_acc: 0.8824\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4919 - acc: 0.8824 - val_loss: 0.5442 - val_acc: 0.8824\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4731 - acc: 0.8824 - val_loss: 0.4981 - val_acc: 0.8529\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4770 - acc: 0.8676 - val_loss: 0.5181 - val_acc: 0.8235\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4734 - acc: 0.8824 - val_loss: 0.5846 - val_acc: 0.8824\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4526 - acc: 0.9118 - val_loss: 0.6810 - val_acc: 0.8235\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4759 - acc: 0.8529 - val_loss: 0.6230 - val_acc: 0.8529\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4686 - acc: 0.8676 - val_loss: 0.6824 - val_acc: 0.8235\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4211 - acc: 0.9559 - val_loss: 0.5236 - val_acc: 0.8824\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4674 - acc: 0.8824 - val_loss: 0.5044 - val_acc: 0.8529\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4846 - acc: 0.8676 - val_loss: 0.5063 - val_acc: 0.8235\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4456 - acc: 0.9118 - val_loss: 0.5573 - val_acc: 0.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4474 - acc: 0.9265 - val_loss: 0.5463 - val_acc: 0.8824\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4727 - acc: 0.9118 - val_loss: 0.5769 - val_acc: 0.8824\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4889 - acc: 0.8971 - val_loss: 0.5241 - val_acc: 0.8824\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4304 - acc: 0.8824 - val_loss: 0.5357 - val_acc: 0.8824\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4411 - acc: 0.9118 - val_loss: 0.5251 - val_acc: 0.8529\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4475 - acc: 0.9265 - val_loss: 0.6143 - val_acc: 0.8235\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4387 - acc: 0.8971 - val_loss: 0.5421 - val_acc: 0.8824\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4308 - acc: 0.9265 - val_loss: 0.5846 - val_acc: 0.8824\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4220 - acc: 0.9118 - val_loss: 0.5036 - val_acc: 0.8529\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4767 - acc: 0.8676 - val_loss: 0.6220 - val_acc: 0.8235\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5177 - acc: 0.8529 - val_loss: 0.4889 - val_acc: 0.8824\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4153 - acc: 0.8824 - val_loss: 0.4960 - val_acc: 0.8529\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4289 - acc: 0.8971 - val_loss: 0.4948 - val_acc: 0.8529\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4387 - acc: 0.9118 - val_loss: 0.5123 - val_acc: 0.8529\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4568 - acc: 0.8971 - val_loss: 0.4923 - val_acc: 0.8529\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4662 - acc: 0.8824 - val_loss: 0.6922 - val_acc: 0.8235\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4787 - acc: 0.9265 - val_loss: 0.4969 - val_acc: 0.8529\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4264 - acc: 0.9265 - val_loss: 0.4783 - val_acc: 0.8529\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4094 - acc: 0.9412 - val_loss: 0.5456 - val_acc: 0.8824\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4411 - acc: 0.8971 - val_loss: 0.5300 - val_acc: 0.8824\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4834 - acc: 0.8676 - val_loss: 0.5459 - val_acc: 0.8824\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4250 - acc: 0.9412 - val_loss: 0.4856 - val_acc: 0.8529\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4151 - acc: 0.8971 - val_loss: 0.6054 - val_acc: 0.8824\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4771 - acc: 0.8971 - val_loss: 0.4965 - val_acc: 0.8235\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4248 - acc: 0.9118 - val_loss: 0.4893 - val_acc: 0.8529\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4067 - acc: 0.9412 - val_loss: 0.5653 - val_acc: 0.8824\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4660 - acc: 0.9118 - val_loss: 0.5179 - val_acc: 0.8529\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4460 - acc: 0.9265 - val_loss: 0.5712 - val_acc: 0.8824\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4671 - acc: 0.8971 - val_loss: 0.5619 - val_acc: 0.8824\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4484 - acc: 0.9265 - val_loss: 0.4958 - val_acc: 0.8235\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4017 - acc: 0.9265 - val_loss: 0.6079 - val_acc: 0.8235\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4774 - acc: 0.9265 - val_loss: 0.4939 - val_acc: 0.8235\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4259 - acc: 0.9118 - val_loss: 0.6143 - val_acc: 0.8235\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4422 - acc: 0.8824 - val_loss: 0.4858 - val_acc: 0.8529\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4829 - acc: 0.8676 - val_loss: 0.5713 - val_acc: 0.8235\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3746 - acc: 0.9706 - val_loss: 0.4931 - val_acc: 0.8235\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4387 - acc: 0.8971 - val_loss: 0.6175 - val_acc: 0.8235\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4154 - acc: 0.9265 - val_loss: 0.5787 - val_acc: 0.8529\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4963 - acc: 0.8824 - val_loss: 0.5404 - val_acc: 0.8824\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4505 - acc: 0.8971 - val_loss: 0.6412 - val_acc: 0.8235\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4859 - acc: 0.8824 - val_loss: 0.5540 - val_acc: 0.8824\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4241 - acc: 0.9412 - val_loss: 0.5010 - val_acc: 0.8529\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4398 - acc: 0.9118 - val_loss: 0.5098 - val_acc: 0.8824\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4235 - acc: 0.8971 - val_loss: 0.5459 - val_acc: 0.8824\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4771 - acc: 0.8824 - val_loss: 0.5369 - val_acc: 0.8824\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4561 - acc: 0.9118 - val_loss: 0.5688 - val_acc: 0.8824\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4203 - acc: 0.8824 - val_loss: 0.5606 - val_acc: 0.8824\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4332 - acc: 0.9118 - val_loss: 0.5015 - val_acc: 0.8235\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4342 - acc: 0.9118 - val_loss: 0.5393 - val_acc: 0.8235\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4337 - acc: 0.9118 - val_loss: 0.5074 - val_acc: 0.8529\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4446 - acc: 0.8971 - val_loss: 0.5031 - val_acc: 0.8529\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4303 - acc: 0.9265 - val_loss: 0.5497 - val_acc: 0.8824\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4143 - acc: 0.9118 - val_loss: 0.4953 - val_acc: 0.8529\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4326 - acc: 0.8824 - val_loss: 0.5297 - val_acc: 0.8824\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4096 - acc: 0.9412 - val_loss: 0.5196 - val_acc: 0.8529\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4549 - acc: 0.8824 - val_loss: 0.5258 - val_acc: 0.8824\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3747 - acc: 0.9412 - val_loss: 0.4874 - val_acc: 0.8235\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4636 - acc: 0.8971 - val_loss: 0.6222 - val_acc: 0.8824\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4069 - acc: 0.8824 - val_loss: 0.5831 - val_acc: 0.8824\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4437 - acc: 0.8824 - val_loss: 0.4930 - val_acc: 0.8235\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4275 - acc: 0.9265 - val_loss: 0.4968 - val_acc: 0.8529\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4069 - acc: 0.9118 - val_loss: 0.4948 - val_acc: 0.8235\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4179 - acc: 0.9118 - val_loss: 0.4985 - val_acc: 0.8529\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4530 - acc: 0.8824 - val_loss: 0.5543 - val_acc: 0.8235\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4803 - acc: 0.8676 - val_loss: 0.6079 - val_acc: 0.8235\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.4807 - acc: 0.8971 - val_loss: 0.5279 - val_acc: 0.8824\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4118 - acc: 0.9265 - val_loss: 0.5315 - val_acc: 0.8824\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.3899 - acc: 0.9265 - val_loss: 0.5326 - val_acc: 0.8529\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4281 - acc: 0.9412 - val_loss: 0.5034 - val_acc: 0.8235\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4265 - acc: 0.8676 - val_loss: 0.5309 - val_acc: 0.8235\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4454 - acc: 0.9265 - val_loss: 0.5707 - val_acc: 0.8824\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4156 - acc: 0.9265 - val_loss: 0.5184 - val_acc: 0.8824\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4037 - acc: 0.9265 - val_loss: 0.6036 - val_acc: 0.8824\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4189 - acc: 0.9118 - val_loss: 0.4969 - val_acc: 0.8235\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 0.4312 - acc: 0.8824 - val_loss: 0.5197 - val_acc: 0.8824\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 0.4831 - acc: 0.9118 - val_loss: 0.5277 - val_acc: 0.8824\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4102 - acc: 0.8971 - val_loss: 0.5214 - val_acc: 0.8529\n",
      "processing fold # 1\n",
      "Train on 68 samples, validate on 34 samples\n",
      "Epoch 1/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 501.9767 - acc: 0.6029 - val_loss: 388.3059 - val_acc: 0.7353\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 326.4954 - acc: 0.6912 - val_loss: 263.5438 - val_acc: 0.8529\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 226.7032 - acc: 0.8088 - val_loss: 188.5118 - val_acc: 0.7647\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 165.0622 - acc: 0.8235 - val_loss: 140.1003 - val_acc: 0.7941\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 124.0957 - acc: 0.8382 - val_loss: 106.9255 - val_acc: 0.8529\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 95.5421 - acc: 0.8824 - val_loss: 83.3858 - val_acc: 0.6765\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 74.6157 - acc: 0.8676 - val_loss: 65.2793 - val_acc: 0.8529\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 58.7875 - acc: 0.9118 - val_loss: 51.6810 - val_acc: 0.7941\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 46.6047 - acc: 0.9265 - val_loss: 41.0741 - val_acc: 0.8235\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 37.0374 - acc: 0.9265 - val_loss: 32.7436 - val_acc: 0.7941\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 29.4641 - acc: 0.8824 - val_loss: 26.0025 - val_acc: 0.8824\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 23.4697 - acc: 0.8971 - val_loss: 20.6768 - val_acc: 0.8529\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 18.6105 - acc: 0.9118 - val_loss: 16.4320 - val_acc: 0.7353\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 14.6984 - acc: 0.8971 - val_loss: 13.0011 - val_acc: 0.7353\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11.5682 - acc: 0.8824 - val_loss: 10.1663 - val_acc: 0.8529\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9.0334 - acc: 0.8971 - val_loss: 7.8962 - val_acc: 0.8529\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 7.0053 - acc: 0.8971 - val_loss: 6.1239 - val_acc: 0.8824\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 5.3920 - acc: 0.8971 - val_loss: 4.7056 - val_acc: 0.8824\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 4.1224 - acc: 0.8529 - val_loss: 3.6180 - val_acc: 0.8235\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 3.1277 - acc: 0.8971 - val_loss: 2.7925 - val_acc: 0.7941\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 2.3736 - acc: 0.8824 - val_loss: 2.1498 - val_acc: 0.7647\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.8181 - acc: 0.8529 - val_loss: 1.7071 - val_acc: 0.7941\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.3927 - acc: 0.8971 - val_loss: 1.3237 - val_acc: 0.8529\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1157 - acc: 0.8971 - val_loss: 1.1359 - val_acc: 0.7647\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.9198 - acc: 0.9265 - val_loss: 0.9142 - val_acc: 0.8529\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.7622 - acc: 0.8824 - val_loss: 0.8581 - val_acc: 0.8235\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6996 - acc: 0.8676 - val_loss: 0.8060 - val_acc: 0.7647\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6724 - acc: 0.8382 - val_loss: 0.7115 - val_acc: 0.8235\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6127 - acc: 0.8676 - val_loss: 0.7646 - val_acc: 0.7353\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6175 - acc: 0.8529 - val_loss: 0.7151 - val_acc: 0.8529\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6487 - acc: 0.8676 - val_loss: 0.7008 - val_acc: 0.7941\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5591 - acc: 0.9118 - val_loss: 0.7758 - val_acc: 0.7353\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5114 - acc: 0.8971 - val_loss: 0.6625 - val_acc: 0.8529\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5929 - acc: 0.8676 - val_loss: 0.7040 - val_acc: 0.7941\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5570 - acc: 0.8824 - val_loss: 0.9228 - val_acc: 0.6471\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5571 - acc: 0.8824 - val_loss: 0.6683 - val_acc: 0.8824\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5789 - acc: 0.8529 - val_loss: 0.7842 - val_acc: 0.7059\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5162 - acc: 0.9265 - val_loss: 1.0767 - val_acc: 0.5588\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5755 - acc: 0.8529 - val_loss: 0.6519 - val_acc: 0.8529\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5675 - acc: 0.8824 - val_loss: 0.6632 - val_acc: 0.8529\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5455 - acc: 0.8676 - val_loss: 0.6491 - val_acc: 0.8824\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5374 - acc: 0.8824 - val_loss: 0.6697 - val_acc: 0.7941\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5111 - acc: 0.8824 - val_loss: 0.6439 - val_acc: 0.8529\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5128 - acc: 0.8971 - val_loss: 0.6572 - val_acc: 0.8824\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5534 - acc: 0.8824 - val_loss: 0.6855 - val_acc: 0.7941\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5025 - acc: 0.9412 - val_loss: 0.6751 - val_acc: 0.8529\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5537 - acc: 0.8824 - val_loss: 0.6490 - val_acc: 0.8529\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5193 - acc: 0.8676 - val_loss: 0.8005 - val_acc: 0.7353\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5535 - acc: 0.8676 - val_loss: 0.6547 - val_acc: 0.8235\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5647 - acc: 0.8971 - val_loss: 0.6978 - val_acc: 0.7647\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5094 - acc: 0.9118 - val_loss: 0.6775 - val_acc: 0.7647\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4855 - acc: 0.9118 - val_loss: 0.6245 - val_acc: 0.8529\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5197 - acc: 0.8676 - val_loss: 0.6992 - val_acc: 0.7647\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5285 - acc: 0.8676 - val_loss: 0.6139 - val_acc: 0.8824\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5157 - acc: 0.8824 - val_loss: 0.7012 - val_acc: 0.7647\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5291 - acc: 0.8676 - val_loss: 0.6212 - val_acc: 0.8235\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4593 - acc: 0.9265 - val_loss: 0.6083 - val_acc: 0.8824\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5462 - acc: 0.8676 - val_loss: 0.6058 - val_acc: 0.8529\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5055 - acc: 0.8824 - val_loss: 0.6123 - val_acc: 0.8824\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4813 - acc: 0.9118 - val_loss: 0.6248 - val_acc: 0.8824\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4743 - acc: 0.8824 - val_loss: 0.6136 - val_acc: 0.8529\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5009 - acc: 0.9118 - val_loss: 0.6226 - val_acc: 0.8529\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5101 - acc: 0.8676 - val_loss: 0.8261 - val_acc: 0.6765\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5555 - acc: 0.8088 - val_loss: 0.6239 - val_acc: 0.8235\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5500 - acc: 0.8971 - val_loss: 0.6619 - val_acc: 0.7941\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4559 - acc: 0.9706 - val_loss: 0.6699 - val_acc: 0.7941\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4582 - acc: 0.8824 - val_loss: 0.6615 - val_acc: 0.7647\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4520 - acc: 0.8971 - val_loss: 0.6254 - val_acc: 0.8235\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4920 - acc: 0.9118 - val_loss: 0.7053 - val_acc: 0.7941\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4843 - acc: 0.8971 - val_loss: 0.6472 - val_acc: 0.8824\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4552 - acc: 0.8824 - val_loss: 0.5997 - val_acc: 0.8235\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5438 - acc: 0.8235 - val_loss: 0.5996 - val_acc: 0.8235\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5072 - acc: 0.8676 - val_loss: 0.6657 - val_acc: 0.7941\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5126 - acc: 0.8971 - val_loss: 0.6553 - val_acc: 0.8235\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5119 - acc: 0.8676 - val_loss: 0.7052 - val_acc: 0.7647\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5488 - acc: 0.8676 - val_loss: 0.6041 - val_acc: 0.8235\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4869 - acc: 0.8971 - val_loss: 0.6702 - val_acc: 0.7647\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4336 - acc: 0.9412 - val_loss: 0.5890 - val_acc: 0.8529\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4329 - acc: 0.9265 - val_loss: 0.7970 - val_acc: 0.6765\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4486 - acc: 0.9118 - val_loss: 0.5948 - val_acc: 0.8529\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4797 - acc: 0.8824 - val_loss: 0.6119 - val_acc: 0.7941\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4742 - acc: 0.8824 - val_loss: 0.6733 - val_acc: 0.7941\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4421 - acc: 0.9118 - val_loss: 0.6114 - val_acc: 0.7941\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4823 - acc: 0.8971 - val_loss: 0.5978 - val_acc: 0.8235\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4433 - acc: 0.9412 - val_loss: 0.6761 - val_acc: 0.7941\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4914 - acc: 0.8824 - val_loss: 0.7479 - val_acc: 0.7353\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4978 - acc: 0.8824 - val_loss: 0.6034 - val_acc: 0.8235\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4500 - acc: 0.8971 - val_loss: 0.6313 - val_acc: 0.8235\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4583 - acc: 0.8824 - val_loss: 0.7488 - val_acc: 0.7353\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4702 - acc: 0.8971 - val_loss: 1.1486 - val_acc: 0.5588\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5250 - acc: 0.8529 - val_loss: 0.6821 - val_acc: 0.8235\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4361 - acc: 0.9118 - val_loss: 0.6669 - val_acc: 0.7941\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4779 - acc: 0.9118 - val_loss: 0.6039 - val_acc: 0.8235\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.8824 - val_loss: 0.5938 - val_acc: 0.8824\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5195 - acc: 0.8824 - val_loss: 0.6060 - val_acc: 0.8235\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4284 - acc: 0.9118 - val_loss: 0.6751 - val_acc: 0.7647\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4243 - acc: 0.9265 - val_loss: 0.6722 - val_acc: 0.8235\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4431 - acc: 0.9118 - val_loss: 0.6030 - val_acc: 0.8235\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4377 - acc: 0.8824 - val_loss: 0.6056 - val_acc: 0.8235\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4634 - acc: 0.8824 - val_loss: 0.5844 - val_acc: 0.7941\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4877 - acc: 0.8971 - val_loss: 0.6542 - val_acc: 0.7941\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4529 - acc: 0.8824 - val_loss: 0.5938 - val_acc: 0.8529\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3840 - acc: 0.9412 - val_loss: 0.5920 - val_acc: 0.8235\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5234 - acc: 0.8676 - val_loss: 0.6261 - val_acc: 0.7941\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5631 - acc: 0.8382 - val_loss: 0.5939 - val_acc: 0.8235\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4688 - acc: 0.9118 - val_loss: 0.6411 - val_acc: 0.7941\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4643 - acc: 0.8971 - val_loss: 0.7290 - val_acc: 0.6765\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4772 - acc: 0.8676 - val_loss: 0.6403 - val_acc: 0.8235\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4339 - acc: 0.9265 - val_loss: 0.5688 - val_acc: 0.8529\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4169 - acc: 0.9412 - val_loss: 0.7197 - val_acc: 0.7353\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4736 - acc: 0.9265 - val_loss: 0.5972 - val_acc: 0.7941\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4362 - acc: 0.8971 - val_loss: 0.5907 - val_acc: 0.8529\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3981 - acc: 0.9706 - val_loss: 0.5652 - val_acc: 0.8235\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3816 - acc: 0.9559 - val_loss: 0.5782 - val_acc: 0.8529\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4574 - acc: 0.9118 - val_loss: 0.6644 - val_acc: 0.7647\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4206 - acc: 0.9118 - val_loss: 0.5847 - val_acc: 0.8235\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4032 - acc: 0.9118 - val_loss: 0.6086 - val_acc: 0.8235\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4555 - acc: 0.9265 - val_loss: 0.6163 - val_acc: 0.8235\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5167 - acc: 0.8824 - val_loss: 0.6225 - val_acc: 0.7941\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4249 - acc: 0.8971 - val_loss: 0.5779 - val_acc: 0.8235\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4633 - acc: 0.9118 - val_loss: 0.5873 - val_acc: 0.8235\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4373 - acc: 0.9412 - val_loss: 0.5895 - val_acc: 0.8235\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4202 - acc: 0.9412 - val_loss: 0.6049 - val_acc: 0.8529\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5007 - acc: 0.8676 - val_loss: 0.6042 - val_acc: 0.8235\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4157 - acc: 0.9412 - val_loss: 0.6561 - val_acc: 0.7647\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4715 - acc: 0.8971 - val_loss: 0.5952 - val_acc: 0.8235\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4579 - acc: 0.8676 - val_loss: 0.5882 - val_acc: 0.7941\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3919 - acc: 0.9853 - val_loss: 0.6132 - val_acc: 0.8235\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4415 - acc: 0.8676 - val_loss: 0.6743 - val_acc: 0.7353\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4558 - acc: 0.8971 - val_loss: 0.5962 - val_acc: 0.8235\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4276 - acc: 0.8676 - val_loss: 0.5857 - val_acc: 0.7941\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4620 - acc: 0.9412 - val_loss: 0.6044 - val_acc: 0.8529\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4267 - acc: 0.9118 - val_loss: 0.6120 - val_acc: 0.8529\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4544 - acc: 0.8971 - val_loss: 0.6332 - val_acc: 0.8235\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4543 - acc: 0.9265 - val_loss: 0.5831 - val_acc: 0.7941\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4320 - acc: 0.9265 - val_loss: 0.5841 - val_acc: 0.8235\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4871 - acc: 0.9265 - val_loss: 0.6350 - val_acc: 0.7647\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4203 - acc: 0.9118 - val_loss: 0.5830 - val_acc: 0.7941\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4650 - acc: 0.8971 - val_loss: 0.5706 - val_acc: 0.8235\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4258 - acc: 0.9265 - val_loss: 0.6317 - val_acc: 0.7941\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4229 - acc: 0.9265 - val_loss: 0.5844 - val_acc: 0.8235\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4063 - acc: 0.9118 - val_loss: 0.7135 - val_acc: 0.7647\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3799 - acc: 0.9412 - val_loss: 0.6501 - val_acc: 0.7941\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4197 - acc: 0.9265 - val_loss: 0.6276 - val_acc: 0.8824\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4411 - acc: 0.9265 - val_loss: 0.6784 - val_acc: 0.7647\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4432 - acc: 0.8971 - val_loss: 0.6353 - val_acc: 0.7941\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3955 - acc: 0.9118 - val_loss: 0.5873 - val_acc: 0.8235\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4289 - acc: 0.9118 - val_loss: 0.5633 - val_acc: 0.8529\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4139 - acc: 0.9559 - val_loss: 0.5748 - val_acc: 0.8235\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3718 - acc: 0.9412 - val_loss: 0.5566 - val_acc: 0.8235\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3807 - acc: 0.9559 - val_loss: 0.5793 - val_acc: 0.8529\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3927 - acc: 0.9412 - val_loss: 0.5721 - val_acc: 0.7941\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4155 - acc: 0.9412 - val_loss: 0.5892 - val_acc: 0.8529\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4562 - acc: 0.9412 - val_loss: 0.5636 - val_acc: 0.8235\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4027 - acc: 0.9118 - val_loss: 0.7867 - val_acc: 0.6765\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4522 - acc: 0.8676 - val_loss: 0.5799 - val_acc: 0.8235\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4323 - acc: 0.8971 - val_loss: 0.5885 - val_acc: 0.8235\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4278 - acc: 0.9265 - val_loss: 0.6309 - val_acc: 0.8235\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4686 - acc: 0.8382 - val_loss: 0.5906 - val_acc: 0.8235\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3958 - acc: 0.9559 - val_loss: 0.6210 - val_acc: 0.8235\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4687 - acc: 0.9118 - val_loss: 0.5709 - val_acc: 0.8529\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4083 - acc: 0.9118 - val_loss: 0.5720 - val_acc: 0.8529\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3917 - acc: 0.8971 - val_loss: 0.6338 - val_acc: 0.7941\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4231 - acc: 0.9265 - val_loss: 0.5697 - val_acc: 0.8235\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3938 - acc: 0.9265 - val_loss: 0.5829 - val_acc: 0.8235\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3735 - acc: 0.9412 - val_loss: 0.6588 - val_acc: 0.7941\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4150 - acc: 0.9265 - val_loss: 0.6118 - val_acc: 0.7941\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4677 - acc: 0.8676 - val_loss: 0.6144 - val_acc: 0.7647\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4629 - acc: 0.9118 - val_loss: 0.6308 - val_acc: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4119 - acc: 0.9118 - val_loss: 0.5786 - val_acc: 0.8235\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4069 - acc: 0.8824 - val_loss: 0.5642 - val_acc: 0.8529\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3964 - acc: 0.8824 - val_loss: 0.6012 - val_acc: 0.8235\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4464 - acc: 0.8971 - val_loss: 0.5861 - val_acc: 0.8235\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4194 - acc: 0.9265 - val_loss: 0.5728 - val_acc: 0.7941\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3965 - acc: 0.9118 - val_loss: 0.5586 - val_acc: 0.8235\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4359 - acc: 0.9265 - val_loss: 0.5782 - val_acc: 0.8529\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3930 - acc: 0.9412 - val_loss: 0.8876 - val_acc: 0.6765\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4831 - acc: 0.8676 - val_loss: 0.5705 - val_acc: 0.7941\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4065 - acc: 0.9265 - val_loss: 0.5799 - val_acc: 0.8235\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3995 - acc: 0.9265 - val_loss: 0.6622 - val_acc: 0.7353\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4335 - acc: 0.8971 - val_loss: 0.5783 - val_acc: 0.7941\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4192 - acc: 0.9118 - val_loss: 0.6124 - val_acc: 0.8235\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3809 - acc: 0.9118 - val_loss: 0.7256 - val_acc: 0.7647\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4475 - acc: 0.8824 - val_loss: 0.6058 - val_acc: 0.8235\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4462 - acc: 0.8676 - val_loss: 0.5782 - val_acc: 0.7941\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3966 - acc: 0.9118 - val_loss: 0.7299 - val_acc: 0.7353\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4692 - acc: 0.8824 - val_loss: 0.5617 - val_acc: 0.7941\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4049 - acc: 0.9265 - val_loss: 0.6203 - val_acc: 0.7941\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4513 - acc: 0.9265 - val_loss: 0.6476 - val_acc: 0.8529\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4963 - acc: 0.8529 - val_loss: 0.6057 - val_acc: 0.8235\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3664 - acc: 0.9706 - val_loss: 0.6603 - val_acc: 0.7941\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4749 - acc: 0.8824 - val_loss: 0.6264 - val_acc: 0.8235\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3754 - acc: 0.8971 - val_loss: 0.5976 - val_acc: 0.7941\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3734 - acc: 0.9706 - val_loss: 0.5943 - val_acc: 0.7941\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4161 - acc: 0.9706 - val_loss: 0.5894 - val_acc: 0.8235\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3433 - acc: 0.9853 - val_loss: 0.8294 - val_acc: 0.7353\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4406 - acc: 0.8971 - val_loss: 0.6240 - val_acc: 0.8235\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4175 - acc: 0.9118 - val_loss: 0.7125 - val_acc: 0.7353\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4184 - acc: 0.9265 - val_loss: 0.6024 - val_acc: 0.8529\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.9412 - val_loss: 0.5717 - val_acc: 0.7941\n",
      "processing fold # 2\n",
      "Train on 68 samples, validate on 34 samples\n",
      "Epoch 1/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 495.4768 - acc: 0.6324 - val_loss: 378.6866 - val_acc: 0.5588\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 315.2731 - acc: 0.6765 - val_loss: 251.4252 - val_acc: 0.8235\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 214.9288 - acc: 0.7941 - val_loss: 177.1698 - val_acc: 0.7353\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 154.3970 - acc: 0.7794 - val_loss: 130.1607 - val_acc: 0.9118\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 115.2694 - acc: 0.8382 - val_loss: 98.7787 - val_acc: 0.9412\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 88.2395 - acc: 0.8529 - val_loss: 76.5195 - val_acc: 0.9412\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 68.8799 - acc: 0.8529 - val_loss: 60.1694 - val_acc: 0.9412\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 54.4304 - acc: 0.8529 - val_loss: 47.7523 - val_acc: 0.9118\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 43.3400 - acc: 0.7941 - val_loss: 38.1565 - val_acc: 0.8824\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 34.6053 - acc: 0.8382 - val_loss: 30.4129 - val_acc: 0.9706\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 27.6513 - acc: 0.8382 - val_loss: 24.2800 - val_acc: 0.9412\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 22.1019 - acc: 0.8382 - val_loss: 19.3410 - val_acc: 0.9412\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 17.6048 - acc: 0.8529 - val_loss: 15.3096 - val_acc: 0.9412\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13.9047 - acc: 0.8676 - val_loss: 12.0391 - val_acc: 0.9412\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10.9439 - acc: 0.8235 - val_loss: 9.4267 - val_acc: 0.9412\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8.5529 - acc: 0.8529 - val_loss: 7.2805 - val_acc: 0.9706\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 6.6359 - acc: 0.8676 - val_loss: 5.6115 - val_acc: 0.9706\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.0877 - acc: 0.8529 - val_loss: 4.2757 - val_acc: 0.8824\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 3.8807 - acc: 0.9118 - val_loss: 3.2194 - val_acc: 0.9412\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 2.9637 - acc: 0.8824 - val_loss: 2.4225 - val_acc: 0.9706\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 2.3081 - acc: 0.7941 - val_loss: 1.8579 - val_acc: 0.9118\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 1.8289 - acc: 0.7941 - val_loss: 1.4130 - val_acc: 0.9706\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 1.3964 - acc: 0.8088 - val_loss: 1.1814 - val_acc: 0.8529\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 1.1686 - acc: 0.7647 - val_loss: 0.8951 - val_acc: 0.9412\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.9462 - acc: 0.8824 - val_loss: 0.7609 - val_acc: 0.8824\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.8545 - acc: 0.8382 - val_loss: 0.6392 - val_acc: 0.9412\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.7966 - acc: 0.8088 - val_loss: 0.5834 - val_acc: 0.9706\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7313 - acc: 0.8088 - val_loss: 0.5694 - val_acc: 0.9118\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6913 - acc: 0.8382 - val_loss: 0.5369 - val_acc: 0.9412\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.8088 - val_loss: 0.5356 - val_acc: 0.9412\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6823 - acc: 0.8676 - val_loss: 0.4951 - val_acc: 0.9412\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6690 - acc: 0.8529 - val_loss: 0.5022 - val_acc: 0.9118\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6803 - acc: 0.7941 - val_loss: 0.5033 - val_acc: 0.9412\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6500 - acc: 0.8382 - val_loss: 0.5083 - val_acc: 0.9706\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.8382 - val_loss: 0.4840 - val_acc: 0.9412\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6652 - acc: 0.7941 - val_loss: 0.4742 - val_acc: 0.9412\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6555 - acc: 0.8529 - val_loss: 0.4808 - val_acc: 0.9412\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6237 - acc: 0.8676 - val_loss: 0.4798 - val_acc: 0.9412\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6828 - acc: 0.8382 - val_loss: 0.4628 - val_acc: 0.9412\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6144 - acc: 0.8971 - val_loss: 0.4512 - val_acc: 0.9706\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5966 - acc: 0.8382 - val_loss: 0.4767 - val_acc: 0.8824\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6822 - acc: 0.8088 - val_loss: 0.4595 - val_acc: 0.9706\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6028 - acc: 0.8676 - val_loss: 0.4640 - val_acc: 0.9118\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6051 - acc: 0.8382 - val_loss: 0.4402 - val_acc: 0.9412\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6262 - acc: 0.8824 - val_loss: 0.4483 - val_acc: 0.9412\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6338 - acc: 0.8382 - val_loss: 0.4878 - val_acc: 0.8824\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6722 - acc: 0.7647 - val_loss: 0.4811 - val_acc: 0.9412\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5842 - acc: 0.8235 - val_loss: 0.4731 - val_acc: 0.8824\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6023 - acc: 0.8382 - val_loss: 0.4373 - val_acc: 0.9706\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6854 - acc: 0.8088 - val_loss: 0.5058 - val_acc: 0.8529\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6269 - acc: 0.8088 - val_loss: 0.4443 - val_acc: 0.9706\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6159 - acc: 0.8529 - val_loss: 0.4746 - val_acc: 0.8529\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5894 - acc: 0.8676 - val_loss: 0.4220 - val_acc: 0.9706\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6345 - acc: 0.8088 - val_loss: 0.4537 - val_acc: 0.9118\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6474 - acc: 0.8235 - val_loss: 0.4435 - val_acc: 0.9412\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5932 - acc: 0.8676 - val_loss: 0.4392 - val_acc: 0.9412\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5968 - acc: 0.8676 - val_loss: 0.4723 - val_acc: 0.9412\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6234 - acc: 0.7941 - val_loss: 0.4404 - val_acc: 0.9412\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6004 - acc: 0.8529 - val_loss: 0.4647 - val_acc: 0.9706\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6334 - acc: 0.8235 - val_loss: 0.4393 - val_acc: 0.9706\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6688 - acc: 0.7941 - val_loss: 0.4513 - val_acc: 0.9412\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5998 - acc: 0.8382 - val_loss: 0.4405 - val_acc: 0.9706\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5955 - acc: 0.8382 - val_loss: 0.4446 - val_acc: 0.9412\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6022 - acc: 0.8676 - val_loss: 0.4266 - val_acc: 0.9706\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6070 - acc: 0.8382 - val_loss: 0.4244 - val_acc: 0.9412\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6016 - acc: 0.8382 - val_loss: 0.4387 - val_acc: 0.9412\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5838 - acc: 0.8529 - val_loss: 0.4212 - val_acc: 0.9706\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5945 - acc: 0.8382 - val_loss: 0.4141 - val_acc: 0.9412\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5346 - acc: 0.8971 - val_loss: 0.4058 - val_acc: 0.9706\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6575 - acc: 0.7794 - val_loss: 0.4117 - val_acc: 0.9706\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5988 - acc: 0.8088 - val_loss: 0.4938 - val_acc: 0.8529\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5772 - acc: 0.8676 - val_loss: 0.4339 - val_acc: 0.9706\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6165 - acc: 0.8382 - val_loss: 0.4125 - val_acc: 0.9706\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6043 - acc: 0.8088 - val_loss: 0.4322 - val_acc: 0.9412\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5943 - acc: 0.8382 - val_loss: 0.4094 - val_acc: 0.9412\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6009 - acc: 0.8088 - val_loss: 0.4096 - val_acc: 0.9412\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5899 - acc: 0.8382 - val_loss: 0.4202 - val_acc: 0.9706\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5768 - acc: 0.8382 - val_loss: 0.4086 - val_acc: 0.9412\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6076 - acc: 0.8088 - val_loss: 0.4237 - val_acc: 0.9706\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5935 - acc: 0.8529 - val_loss: 0.4315 - val_acc: 0.9412\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5925 - acc: 0.8971 - val_loss: 0.4149 - val_acc: 0.9412\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5677 - acc: 0.8676 - val_loss: 0.4073 - val_acc: 0.9706\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5559 - acc: 0.8382 - val_loss: 0.4553 - val_acc: 0.8824\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5621 - acc: 0.8529 - val_loss: 0.4377 - val_acc: 0.9412\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5790 - acc: 0.7941 - val_loss: 0.4046 - val_acc: 0.9412\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6058 - acc: 0.8529 - val_loss: 0.4570 - val_acc: 0.8529\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6435 - acc: 0.8382 - val_loss: 0.4080 - val_acc: 0.9412\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5616 - acc: 0.8088 - val_loss: 0.4118 - val_acc: 0.9706\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5448 - acc: 0.8382 - val_loss: 0.4013 - val_acc: 0.9706\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5382 - acc: 0.8382 - val_loss: 0.3956 - val_acc: 0.9706\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5760 - acc: 0.8235 - val_loss: 0.4063 - val_acc: 0.9412\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5135 - acc: 0.8971 - val_loss: 0.3938 - val_acc: 0.9412\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6145 - acc: 0.8676 - val_loss: 0.4097 - val_acc: 0.9412\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5458 - acc: 0.8824 - val_loss: 0.4004 - val_acc: 0.9706\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5565 - acc: 0.8529 - val_loss: 0.4028 - val_acc: 0.9706\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5899 - acc: 0.8529 - val_loss: 0.3921 - val_acc: 0.9706\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5961 - acc: 0.7794 - val_loss: 0.3912 - val_acc: 0.9706\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5590 - acc: 0.8824 - val_loss: 0.3869 - val_acc: 0.9412\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5429 - acc: 0.8382 - val_loss: 0.3872 - val_acc: 0.9706\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5338 - acc: 0.8824 - val_loss: 0.4039 - val_acc: 0.9412\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5500 - acc: 0.8529 - val_loss: 0.4150 - val_acc: 0.9412\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5799 - acc: 0.8235 - val_loss: 0.3977 - val_acc: 0.9412\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5586 - acc: 0.8676 - val_loss: 0.3950 - val_acc: 0.9412\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6099 - acc: 0.7647 - val_loss: 0.4127 - val_acc: 0.9412\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5742 - acc: 0.8382 - val_loss: 0.4110 - val_acc: 0.9412\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5609 - acc: 0.8529 - val_loss: 0.3966 - val_acc: 0.9412\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5691 - acc: 0.8382 - val_loss: 0.3921 - val_acc: 0.9706\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5318 - acc: 0.8235 - val_loss: 0.3974 - val_acc: 0.9706\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5249 - acc: 0.8676 - val_loss: 0.3971 - val_acc: 0.9412\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5444 - acc: 0.8824 - val_loss: 0.3954 - val_acc: 0.9706\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5268 - acc: 0.8971 - val_loss: 0.3877 - val_acc: 0.9412\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5642 - acc: 0.8529 - val_loss: 0.3906 - val_acc: 0.9706\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5639 - acc: 0.7941 - val_loss: 0.3887 - val_acc: 0.9706\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5309 - acc: 0.8824 - val_loss: 0.3937 - val_acc: 0.9706\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5344 - acc: 0.8529 - val_loss: 0.4188 - val_acc: 0.9412\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6123 - acc: 0.8382 - val_loss: 0.3922 - val_acc: 0.9706\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5668 - acc: 0.8676 - val_loss: 0.3888 - val_acc: 0.9706\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6050 - acc: 0.8235 - val_loss: 0.3932 - val_acc: 0.9412\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5930 - acc: 0.7647 - val_loss: 0.4175 - val_acc: 0.9412\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5523 - acc: 0.8529 - val_loss: 0.3886 - val_acc: 0.9412\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5391 - acc: 0.8971 - val_loss: 0.3790 - val_acc: 0.9706\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5697 - acc: 0.8235 - val_loss: 0.3786 - val_acc: 0.9706\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5323 - acc: 0.8824 - val_loss: 0.3948 - val_acc: 0.9412\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5715 - acc: 0.8529 - val_loss: 0.3761 - val_acc: 0.9706\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5596 - acc: 0.8676 - val_loss: 0.3955 - val_acc: 0.9412\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5176 - acc: 0.8529 - val_loss: 0.3695 - val_acc: 0.9706\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5300 - acc: 0.8529 - val_loss: 0.3720 - val_acc: 0.9706\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6043 - acc: 0.7647 - val_loss: 0.4047 - val_acc: 0.9706\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5432 - acc: 0.8235 - val_loss: 0.3872 - val_acc: 0.9412\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5224 - acc: 0.8676 - val_loss: 0.3745 - val_acc: 0.9412\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5669 - acc: 0.8382 - val_loss: 0.4017 - val_acc: 0.9118\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5314 - acc: 0.8382 - val_loss: 0.3728 - val_acc: 0.9706\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5262 - acc: 0.8676 - val_loss: 0.3768 - val_acc: 0.9412\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5092 - acc: 0.8971 - val_loss: 0.3720 - val_acc: 0.9706\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5540 - acc: 0.8824 - val_loss: 0.3783 - val_acc: 0.9412\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5091 - acc: 0.8676 - val_loss: 0.3988 - val_acc: 0.9412\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5505 - acc: 0.8824 - val_loss: 0.3712 - val_acc: 0.9706\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5141 - acc: 0.8824 - val_loss: 0.3830 - val_acc: 0.9706\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5665 - acc: 0.8676 - val_loss: 0.3786 - val_acc: 0.9412\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5470 - acc: 0.8235 - val_loss: 0.3908 - val_acc: 0.9412\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5216 - acc: 0.8529 - val_loss: 0.3702 - val_acc: 0.9706\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5354 - acc: 0.8824 - val_loss: 0.3676 - val_acc: 0.9706\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5829 - acc: 0.8235 - val_loss: 0.3810 - val_acc: 0.9706\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5060 - acc: 0.8529 - val_loss: 0.3654 - val_acc: 0.9706\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5299 - acc: 0.8971 - val_loss: 0.3952 - val_acc: 0.9412\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5488 - acc: 0.8676 - val_loss: 0.3780 - val_acc: 0.9706\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5092 - acc: 0.8529 - val_loss: 0.3778 - val_acc: 0.9412\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4893 - acc: 0.8529 - val_loss: 0.3622 - val_acc: 0.9412\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4695 - acc: 0.9118 - val_loss: 0.3778 - val_acc: 0.9706\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5326 - acc: 0.8676 - val_loss: 0.3737 - val_acc: 0.9412\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5045 - acc: 0.8971 - val_loss: 0.3555 - val_acc: 0.9706\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5419 - acc: 0.9118 - val_loss: 0.3742 - val_acc: 0.9412\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4953 - acc: 0.8676 - val_loss: 0.3550 - val_acc: 0.9706\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4961 - acc: 0.8971 - val_loss: 0.3609 - val_acc: 0.9706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5602 - acc: 0.8676 - val_loss: 0.3749 - val_acc: 0.9706\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6100 - acc: 0.8088 - val_loss: 0.3727 - val_acc: 0.9412\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5291 - acc: 0.8971 - val_loss: 0.3666 - val_acc: 0.9412\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4994 - acc: 0.9118 - val_loss: 0.3631 - val_acc: 0.9412\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5014 - acc: 0.8676 - val_loss: 0.3553 - val_acc: 0.9706\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5346 - acc: 0.8382 - val_loss: 0.3616 - val_acc: 0.9706\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4757 - acc: 0.8824 - val_loss: 0.3696 - val_acc: 0.9412\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4904 - acc: 0.8676 - val_loss: 0.3505 - val_acc: 0.9706\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4995 - acc: 0.8824 - val_loss: 0.3602 - val_acc: 0.9706\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5342 - acc: 0.8382 - val_loss: 0.3729 - val_acc: 0.9706\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5094 - acc: 0.8824 - val_loss: 0.3912 - val_acc: 0.9118\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5045 - acc: 0.8824 - val_loss: 0.3788 - val_acc: 0.9412\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5548 - acc: 0.8088 - val_loss: 0.3678 - val_acc: 0.9412\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5663 - acc: 0.8529 - val_loss: 0.3589 - val_acc: 0.9706\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5343 - acc: 0.8529 - val_loss: 0.3785 - val_acc: 0.9412\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5373 - acc: 0.8382 - val_loss: 0.3676 - val_acc: 0.9412\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5391 - acc: 0.8529 - val_loss: 0.3554 - val_acc: 0.9706\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5395 - acc: 0.8529 - val_loss: 0.3797 - val_acc: 0.9706\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5243 - acc: 0.8382 - val_loss: 0.3609 - val_acc: 0.9706\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5417 - acc: 0.8382 - val_loss: 0.3602 - val_acc: 0.9706\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5257 - acc: 0.8382 - val_loss: 0.3875 - val_acc: 0.9706\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4774 - acc: 0.8824 - val_loss: 0.3509 - val_acc: 0.9706\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5136 - acc: 0.9118 - val_loss: 0.3719 - val_acc: 0.9412\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5462 - acc: 0.8235 - val_loss: 0.3586 - val_acc: 0.9412\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5575 - acc: 0.8235 - val_loss: 0.3694 - val_acc: 0.9412\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4926 - acc: 0.8235 - val_loss: 0.3562 - val_acc: 0.9706\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4790 - acc: 0.8824 - val_loss: 0.3843 - val_acc: 0.9412\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5812 - acc: 0.8676 - val_loss: 0.3622 - val_acc: 0.9412\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5362 - acc: 0.8971 - val_loss: 0.3618 - val_acc: 0.9706\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5709 - acc: 0.8824 - val_loss: 0.3631 - val_acc: 0.9412\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5535 - acc: 0.8235 - val_loss: 0.3625 - val_acc: 0.9412\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5716 - acc: 0.8382 - val_loss: 0.3795 - val_acc: 0.9706\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5167 - acc: 0.8676 - val_loss: 0.3585 - val_acc: 0.9706\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6186 - acc: 0.8088 - val_loss: 0.3659 - val_acc: 0.9412\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5074 - acc: 0.8529 - val_loss: 0.3658 - val_acc: 0.9706\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4870 - acc: 0.8971 - val_loss: 0.3478 - val_acc: 0.9706\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5538 - acc: 0.8676 - val_loss: 0.3624 - val_acc: 0.9412\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5652 - acc: 0.8235 - val_loss: 0.3602 - val_acc: 0.9706\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4845 - acc: 0.8971 - val_loss: 0.3502 - val_acc: 0.9706\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4848 - acc: 0.8382 - val_loss: 0.3658 - val_acc: 0.9412\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4899 - acc: 0.8971 - val_loss: 0.3582 - val_acc: 0.9706\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4813 - acc: 0.8676 - val_loss: 0.4104 - val_acc: 0.9706\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5308 - acc: 0.8382 - val_loss: 0.3632 - val_acc: 0.9706\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5146 - acc: 0.8824 - val_loss: 0.3481 - val_acc: 0.9706\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.5488 - acc: 0.8529 - val_loss: 0.3890 - val_acc: 0.9412\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.4979 - acc: 0.9118 - val_loss: 0.3467 - val_acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "k = 3\n",
    "num_val_samples = len(train_data) // k\n",
    "acc_historys = []\n",
    "val_acc_historys = []\n",
    "loss_historys = []\n",
    "val_loss_historys = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=5, verbose=1)\n",
    "    \n",
    "    acc_history = history.history['acc']\n",
    "    val_acc_history = history.history['val_acc']\n",
    "    acc_historys.append(acc_history)\n",
    "    val_acc_historys.append(val_acc_history)\n",
    "    \n",
    "    loss_history = history.history['loss']\n",
    "    val_loss_history = history.history['val_loss']\n",
    "    loss_historys.append(loss_history)\n",
    "    val_loss_historys.append(val_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 92.16%\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "scores = model.evaluate(train_data, train_targets, verbose=0)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为图片提供数据源\n",
    "average_acc_history = [\n",
    "    np.mean([x[i] for x in acc_historys]) for i in range(num_epochs)]\n",
    "average_val_acc_history = [\n",
    "    np.mean([x[i] for x in val_acc_historys]) for i in range(num_epochs)]\n",
    "\n",
    "average_loss_history = [\n",
    "    np.mean([x[i] for x in loss_historys]) for i in range(num_epochs)]\n",
    "average_val_loss_history = [\n",
    "    np.mean([x[i] for x in val_loss_historys]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# accuracy的历史\n",
    "plt.plot(average_acc_history)\n",
    "plt.plot(average_val_acc_history)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# loss的历史\n",
    "plt.plot(average_loss_history)\n",
    "plt.plot(average_val_loss_history)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
